install.packages("learnr")
dataset_full
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
unlink("index_cache", recursive = TRUE)
unlink("index_cache", recursive = TRUE)
install.packages("knitr")
install.packages("knitr")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
install.packages("knitr")
install.packages("knitr")
library(knitr)
install.packages("xfun")
install.packages("xfun")
library(xfun)
library(knitr)
install.packages("knitr")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
install.packages("xfun")
install.packages("xfun")
library(xfun)
library(knitr)
libpaths()
libPaths()
.libPaths()
remotes::install_github('yihui/knitr')
remotes::install_github('yihui/knitr')
remotes::install_github('yihui/knitr'), force=TRUE
remotes::install_github('yihui/knitr')
force = TRUE
remotes::install_github('yihui/knitr', force=TRUE)
install.packages('xfun', repos = 'https://yihui.r-universe.dev').
install.packages('xfun', repos = 'https://yihui.r-universe.dev')
install.packages("xfun", repos = "https://yihui.r-universe.dev")
install.packages("rmarkdown 2.14")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages('xfun', repos = 'https://yihui.r-universe.dev')
install.packages("xfun", repos = "https://yihui.r-universe.dev")
wd <- "C:\\Users\\39380\\Documents\\GitHub\\MLCM-Replication-Notebook\\docs\\"
setwd(wd)
dataset_full <- read.csv(paste0(wd, "/data/dataset_replication_full_FINAL.csv"), na.strings=c("",".","NA"))
x.cate <- read.csv(paste0(wd, "/data/CATE_dataset.csv"))
names(dataset_full)
set.seed(1)
# Instructions: Change the working directory below (it must be the path to the replication package,
# something like "C:/.../Replication package") and then click 'Source'. The code runs independently.
# The code takes approximately [20] min to run
# The following code reproduces the estimates in the empirical application of Cerqua, Menchetti and Letta (2023)
# starting from the step after the preliminary random forest
# ------------- Change working directory here ---------------------------------------------------------
#wd <- "C:/Users/fiamm/Documents/MLCM/Replication package"
# -----------------------------------------------------------------------------------------------------
old <- Sys.time()
##################################################################################################
## 0. Libraries, Functions & Data loading
##################################################################################################
### Libraries
library(CAST)
library(caret)
library(gbm)
library(elasticnet)
library(pls)
library(stats)
library(utils)
library(randomForest)
library(rpart)
### Custom functions
source(paste0(wd, "/Functions/package.R"))
set.seed(1)
# Instructions: Change the working directory below (it must be the path to the replication package,
# something like "C:/.../Replication package") and then click 'Source'. The code runs independently.
# The code takes approximately [20] min to run
# The following code reproduces the estimates in the empirical application of Cerqua, Menchetti and Letta (2023)
# starting from the step after the preliminary random forest
# ------------- Change working directory here ---------------------------------------------------------
#wd <- "C:/Users/fiamm/Documents/MLCM/Replication package"
# -----------------------------------------------------------------------------------------------------
old <- Sys.time()
##################################################################################################
## 0. Libraries, Functions & Data loading
##################################################################################################
### Libraries
library(CAST)
library(caret)
library(gbm)
library(elasticnet)
library(pls)
library(stats)
library(utils)
library(randomForest)
library(rpart)
### Custom functions
### Data loading
# Full dataset
wd <- "C:\\Users\\39380\\Documents\\GitHub\\MLCM-Replication-Notebook\\docs\\"
setwd(wd)
dataset_full <- read.csv(paste0(wd, "/data/dataset_replication_full_FINAL.csv"), na.strings=c("",".","NA"))
x.cate <- read.csv(paste0(wd, "/data/CATE_dataset.csv"))
# Pre-intervention dataset
dataset_pre_2020 <- subset(dataset_full, year<2020)
# Intervention date
int_date <- 2020
# Comment: this is a 579 X 4 panel dataset (i.e., the number of units in the panel is 579
#          the number of times is 4). The dataset is organized in a a long manner
#          i.e., it has 579 X 4 = 2316 rows, one column for ID variable ('id'),
#          one column for the time variable ('year') and one column for the dependent
#          variable ('std_math_score'). The dataset also contains 154 potential
#          explanatory variables.
##################################################################################################
##  2. Panel Cross Validation
##################################################################################################
num_cov <- 20 # we keep the 20 most predictive variables selected by the preliminary random forest
### 2.2. Setting the tuning parameters of the Machine Learning algorithms
# SGB
gbmGrid <-  expand.grid(interaction.depth = c(1, 2),
n.trees=c(1000, 2000),
shrinkage = c(0.001, 0.002, 0.005),
n.minobsinnode = c(5, 10))
bo <- list(method = "gbm",
tuneGrid = gbmGrid)
# RF
rf <- list(method = "rf",
ntree = 1000)
# LASSO
lassoGrid <- expand.grid(fraction = seq(0.1, 0.9, by = 0.1))
lasso <- list(method = "lasso",
tuneGrid = lassoGrid,
preProc = c("center", "scale"))
# PLS
pls <- list(method = "pls")
### 2.3. Applying Panel Cross Validation to select the best importance threshold and the best
###      performing algorithm based on the RMSE criterion. Note that we include here the whole dataset
###      because the 'PanelCrossValidation' function subsets the data internally via the argument
###      'int_date'. See lines 202 and beyond of 'package.R'.
PCV <- lapply(num_cov, FUN = function(x){
total_columns <- ncol(dataset_full)
xvar <- colnames(dataset_full)[(total_columns-19):total_columns] ;
data <- as.PanelMLCM(y = dataset_full[, "std_math_score"],
timevar = dataset_full[, "year"],
id = dataset_full[, "id"],
x = dataset_full[, xvar], y.lag = 0) ;
rfGrid <- expand.grid(mtry = round(c(ncol(data)/2, ncol(data)/3, ncol(data)/4))) ;
plsGrid <- expand.grid(ncomp = seq(1, (ncol(data)-2), by = 1)) ;
rf$tuneGrid <- rfGrid ;
pls$tuneGrid <- plsGrid ;
PCV <- PanelCrossValidation(data = data, int_date = int_date, ML_methods = list(bo, rf, lasso, pls)) ;
return(PCV)
})
library(MachineControl)
set.seed(1)
# Instructions: Change the working directory below (it must be the path to the replication package,
# something like "C:/.../Replication package") and then click 'Source'. The code runs independently.
# The code takes approximately [20] min to run
# The following code reproduces the estimates in the empirical application of Cerqua, Menchetti and Letta (2023)
# starting from the step after the preliminary random forest
# ------------- Change working directory here ---------------------------------------------------------
#wd <- "C:/Users/fiamm/Documents/MLCM/Replication package"
# -----------------------------------------------------------------------------------------------------
old <- Sys.time()
##################################################################################################
## 0. Libraries, Functions & Data loading
##################################################################################################
### Libraries
library(CAST)
library(caret)
library(gbm)
library(elasticnet)
library(pls)
library(stats)
library(utils)
library(randomForest)
library(rpart)
### Custom functions
### Data loading
# Full dataset
wd <- "C:\\Users\\39380\\Documents\\GitHub\\MLCM-Replication-Notebook\\docs\\"
setwd(wd)
dataset_full <- read.csv(paste0(wd, "/data/dataset_replication_full_FINAL.csv"), na.strings=c("",".","NA"))
x.cate <- read.csv(paste0(wd, "/data/CATE_dataset.csv"))
# Pre-intervention dataset
dataset_pre_2020 <- subset(dataset_full, year<2020)
# Intervention date
int_date <- 2020
# Comment: this is a 579 X 4 panel dataset (i.e., the number of units in the panel is 579
#          the number of times is 4). The dataset is organized in a a long manner
#          i.e., it has 579 X 4 = 2316 rows, one column for ID variable ('id'),
#          one column for the time variable ('year') and one column for the dependent
#          variable ('std_math_score'). The dataset also contains 154 potential
#          explanatory variables.
##################################################################################################
##  2. Panel Cross Validation
##################################################################################################
num_cov <- 20 # we keep the 20 most predictive variables selected by the preliminary random forest
### 2.2. Setting the tuning parameters of the Machine Learning algorithms
# SGB
gbmGrid <-  expand.grid(interaction.depth = c(1, 2),
n.trees=c(1000, 2000),
shrinkage = c(0.001, 0.002, 0.005),
n.minobsinnode = c(5, 10))
bo <- list(method = "gbm",
tuneGrid = gbmGrid)
# RF
rf <- list(method = "rf",
ntree = 1000)
# LASSO
lassoGrid <- expand.grid(fraction = seq(0.1, 0.9, by = 0.1))
lasso <- list(method = "lasso",
tuneGrid = lassoGrid,
preProc = c("center", "scale"))
# PLS
pls <- list(method = "pls")
### 2.3. Applying Panel Cross Validation to select the best importance threshold and the best
###      performing algorithm based on the RMSE criterion. Note that we include here the whole dataset
###      because the 'PanelCrossValidation' function subsets the data internally via the argument
###      'int_date'. See lines 202 and beyond of 'package.R'.
PCV <- lapply(num_cov, FUN = function(x){
total_columns <- ncol(dataset_full)
xvar <- colnames(dataset_full)[(total_columns-19):total_columns] ;
data <- as.PanelMLCM(y = dataset_full[, "std_math_score"],
timevar = dataset_full[, "year"],
id = dataset_full[, "id"],
x = dataset_full[, xvar], y.lag = 0) ;
rfGrid <- expand.grid(mtry = round(c(ncol(data)/2, ncol(data)/3, ncol(data)/4))) ;
plsGrid <- expand.grid(ncomp = seq(1, (ncol(data)-2), by = 1)) ;
rf$tuneGrid <- rfGrid ;
pls$tuneGrid <- plsGrid ;
PCV <- PanelCrossValidation(data = data, int_date = int_date, ML_methods = list(bo, rf, lasso, pls)) ;
return(PCV)
})
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
############################################################################################################
##
##  CODE to replicate the results of the EMPIRICAL APPLICATION in the paper:
##      "THE MACHINE LEARNING CONTROL METHOD FOR COUNTERFACTUAL FORECASTING"
##
##  AUTHORS: Augusto Cerqua*, Marco Letta*, Fiammetta Menchetti**
##
##  DATE: November 2023
##
##  *(Sapienza University of Rome), **(University of Florence)
##
############################################################################################################
rm(list=ls())
set.seed(1)
# Instructions: Change the working directory below (it must be the path to the replication package,
# something like "C:/.../Replication package") and then click 'Source'. The code runs independently.
# The code takes approximately [20] min to run
# The following code reproduces the estimates in the empirical application of Cerqua, Menchetti and Letta (2023)
# starting from the step after the preliminary random forest
# ------------- Change working directory here ---------------------------------------------------------
#wd <- "C:/Users/fiamm/Documents/MLCM/Replication package"
wd <- "C:/Users/39380/Documents/GitHub/MLCM-Replication-Notebook/docs"
setwd(wd)
# -----------------------------------------------------------------------------------------------------
old <- Sys.time()
##################################################################################################
## 0. Libraries, Functions & Data loading
##################################################################################################
### Libraries
library(CAST)
library(caret)
library(gbm)
library(elasticnet)
library(pls)
library(stats)
library(utils)
library(randomForest)
library(rpart)
### Custom functions
source(paste0(wd, "/Functions/package.R"))
### Data loading
# Full dataset
dataset_full <- read.csv(paste0(wd, "/Data/dataset_replication_full_FINAL.csv"), na.strings=c("",".","NA"))
x.cate <- read.csv(paste0(wd, "/Data/CATE_dataset.csv"))
# Pre-intervention dataset
dataset_pre_2020 <- subset(dataset_full, year<2020)
# Intervention date
int_date <- 2020
# Comment: this is a 579 X 4 panel dataset (i.e., the number of units in the panel is 579
#          the number of times is 4). The dataset is organized in a a long manner
#          i.e., it has 579 X 4 = 2316 rows, one column for ID variable ('id'),
#          one column for the time variable ('year') and one column for the dependent
#          variable ('std_math_score'). The dataset also contains 154 potential
#          explanatory variables.
##################################################################################################
##  2. Panel Cross Validation
##################################################################################################
num_cov <- 20 # we keep the 20 most predictive variables selected by the preliminary random forest
### 2.2. Setting the tuning parameters of the Machine Learning algorithms
# SGB
gbmGrid <-  expand.grid(interaction.depth = c(1, 2),
n.trees=c(1000, 2000),
shrinkage = c(0.001, 0.002, 0.005),
n.minobsinnode = c(5, 10))
bo <- list(method = "gbm",
tuneGrid = gbmGrid)
# RF
rf <- list(method = "rf",
ntree = 1000)
# LASSO
lassoGrid <- expand.grid(fraction = seq(0.1, 0.9, by = 0.1))
lasso <- list(method = "lasso",
tuneGrid = lassoGrid,
preProc = c("center", "scale"))
# PLS
pls <- list(method = "pls")
### 2.3. Applying Panel Cross Validation to select the best importance threshold and the best
###      performing algorithm based on the RMSE criterion. Note that we include here the whole dataset
###      because the 'PanelCrossValidation' function subsets the data internally via the argument
###      'int_date'. See lines 202 and beyond of 'package.R'.
PCV <- lapply(num_cov, FUN = function(x){
total_columns <- ncol(dataset_full)
xvar <- colnames(dataset_full)[(total_columns-19):total_columns] ;
data <- as.PanelMLCM(y = dataset_full[, "std_math_score"],
timevar = dataset_full[, "year"],
id = dataset_full[, "id"],
x = dataset_full[, xvar], y.lag = 0) ;
rfGrid <- expand.grid(mtry = round(c(ncol(data)/2, ncol(data)/3, ncol(data)/4))) ;
plsGrid <- expand.grid(ncomp = seq(1, (ncol(data)-2), by = 1)) ;
rf$tuneGrid <- rfGrid ;
pls$tuneGrid <- plsGrid ;
PCV <- PanelCrossValidation(data = data, int_date = int_date, ML_methods = list(bo, rf, lasso, pls)) ;
return(PCV)
})
PCV
metrics <- sapply(PCV, FUN = function(x)(x$best.metric))
ind <- which(metrics == min(metrics))
best <- PCV[[ind]]$best
best
##################################################################################################
##  3. Causal effect estimation
##################################################################################################
### 3.1. Definition of the final dataset, based on the selected variable importance threshold
total_columns <- ncol(dataset_full)
xvar <- colnames(dataset_full)[(total_columns-19):total_columns]
data <- as.PanelMLCM(y = dataset_full[, "std_math_score"],
timevar = dataset_full[, "year"],
id = dataset_full[, "id"],
x = dataset_full[, xvar], y.lag = 0)
### 3.2. Causal effect estimation
causal_effects <- MLCM(data = data, int_date = int_date, inf_type = "block", PCV = best,
nboot = 1, CATE = TRUE, x.cate = x.cate)
# ATE
ate_eff <- c(causal_effects$ate, causal_effects$conf.ate)
names(ate_eff) <- c("ATE", "Lower_bound", "Upper_bound")
ate_eff
# Individual effects
ind_eff <- data.frame(causal_effects$ind.effects)
names(ind_eff) <- c("ID", "IND_EFF")
# CATE
cate_eff <- causal_effects$cate.inf
cate_eff
causal_effects$cate
##################################################################################################
##  4. Savings
##################################################################################################
write.csv(ind_eff, file = paste0(wd, "/Output/individual_effects.csv"))
write.csv(ate_eff, file = paste0(wd, "/Output/ate.csv"))
write.csv(cate_eff, file = paste0(wd, "/Output/cate.csv"))
##################################################################################################
##  5. Placebo
##################################################################################################
# 2019 #
### 3.1. Definition of the final dataset, based on the selected variable importance threshold
dataset_full_2019 <- subset(dataset_full, year<2020)
int_date_2019 <- 2019
data_placebo_2019 <- as.PanelMLCM(y = dataset_full_2019[, "std_math_score"],
timevar = dataset_full_2019[, "year"],
id = dataset_full_2019[, "id"],
x = dataset_full_2019[, xvar], y.lag = 0)
effects_placebo_2019 <- MLCM(data = data_placebo_2019, int_date = int_date_2019, inf_type = "block", PCV = best,
nboot = 1, CATE = FALSE)
# ATE (Placebo 2019)
ate_eff_placebo_2019 <- c(effects_placebo_2019$ate, effects_placebo_2019$conf.ate)
names(ate_eff_placebo_2019) <- c("ATE", "Lower_bound", "Upper_bound")
ate_eff_placebo_2019
# Individual effects (Placebo 2019)
ind_eff_placebo_2019 <- data.frame(effects_placebo_2019$ind.effects)
names(ind_eff_placebo_2019) <- c("ID", "IND_EFF")
write.csv(ind_eff_placebo_2019, file = paste0(wd, "/Output/individual_effects_placebo_2019.csv"))
write.csv(ate_eff_placebo_2019, file = paste0(wd, "/Output/ate_placebo_2019.csv"))
# 2018 #
### 3.1. Definition of the final dataset, based on the selected variable importance threshold
dataset_full_2018 <- subset(dataset_full, year<2019)
int_date_2018 <- 2018
data_placebo_2018 <- as.PanelMLCM(y = dataset_full_2018[, "std_math_score"],
timevar = dataset_full_2018[, "year"],
id = dataset_full_2018[, "id"],
x = dataset_full_2018[, xvar], y.lag = 0)
effects_placebo_2018 <- MLCM(data = data_placebo_2018, int_date = int_date_2018, inf_type = "block", PCV = best,
nboot = 1, CATE = FALSE)
# ATE (Placebo 2018)
ate_eff_placebo_2018 <- c(effects_placebo_2018$ate, effects_placebo_2018$conf.ate)
names(ate_eff_placebo_2018) <- c("ATE", "Lower_bound", "Upper_bound")
ate_eff_placebo_2018
# Individual effects (Placebo 2018)
ind_eff_placebo_2018 <- data.frame(effects_placebo_2018$ind.effects)
names(ind_eff_placebo_2018) <- c("ID", "IND_EFF")
write.csv(ind_eff_placebo_2018, file = paste0(wd, "/Output/individual_effects_placebo_2018.csv"))
write.csv(ate_eff_placebo_2018, file = paste0(wd, "/Output/ate_placebo_2018.csv"))
new <- Sys.time()
new - old
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
source("~/GitHub/MLCM-Replication-Notebook/docs/index.Rmd")
